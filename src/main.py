"""
Ana uygulama - TÃ¼m pipeline'Ä± birleÅŸtirir
"""
import numpy as np
import pandas as pd
import json
from typing import List, Dict, Any, Optional
import os
import sys

# DiÄŸer modÃ¼lleri iÃ§e aktar
from audio_processor import AudioProcessor
from feature_extractor import FeatureExtractor
from speaker_clustering import SpeakerClustering
from gender_classifier import GenderClassifier

class SpeakerDiarizationSystem:
    def __init__(self, config: Dict[str, Any] = None):
        """
        KonuÅŸmacÄ± Diarization Sistemi
        
        Args:
            config: YapÄ±landÄ±rma ayarlarÄ±
        """
        self.config = config or self._default_config()
        
        # Config'den deÄŸerleri gÃ¼venli ÅŸekilde al
        sample_rate = self.config.get('audio', {}).get('sample_rate', 16000)
        clustering_algorithm = self.config.get('clustering', {}).get('algorithm', 'dbscan')
        similarity_threshold = self.config.get('advanced_analysis', {}).get('similarity_threshold', 0.7)
        
        self.audio_processor = AudioProcessor(target_sr=sample_rate)
        self.feature_extractor = FeatureExtractor(sample_rate=sample_rate)
        self.speaker_clustering = SpeakerClustering(
            algorithm=clustering_algorithm,
            similarity_threshold=similarity_threshold
        )
        self.gender_classifier = GenderClassifier()
        
        print("ğŸ‰ GeliÅŸmiÅŸ Speaker Diarization Sistemi baÅŸlatÄ±ldÄ±!")
        print(f"âš™ï¸  Sample Rate: {sample_rate}")
        print(f"âš™ï¸  Clustering Algorithm: {clustering_algorithm}")
        print(f"âš™ï¸  Similarity Threshold: {similarity_threshold}")
    
    def _default_config(self) -> Dict[str, Any]:
        """VarsayÄ±lan yapÄ±landÄ±rma"""
        return {
            'audio': {
                'sample_rate': 16000,
                'min_segment_length': 0.8,  # Daha kÄ±sa segmentlere izin ver
                'max_segment_length': 15.0  # Daha uzun segmentlere izin ver
            },
            'clustering': {
                'algorithm': 'dbscan',
                'min_speakers': 1,
                'max_speakers': 10
            },
            'segmentation': {
                'min_segment_length': 0.8,
                'max_segment_length': 15.0,
                'silence_threshold': 0.015,  # Daha hassas sessizlik tespiti
                'min_silence_length': 0.3
            },
            'gender_classification': {
                'male_pitch_range': [80, 160],
                'female_pitch_range': [150, 280]
            },
            'advanced_analysis': {
                'similarity_threshold': 0.6,  # Daha dÃ¼ÅŸÃ¼k eÅŸik
                'min_speaker_segments': 1,    # 1 segmentli konuÅŸmacÄ±lara izin ver
                'confidence_threshold': 0.4
            }
        }
    
    def process_audio_file(self, audio_path: str) -> Dict[str, Any]:
        """
        GeliÅŸmiÅŸ ses analizi - TÃ¼m bilgileri dÃ¶ndÃ¼r
        
        Args:
            audio_path: Ses dosyasÄ± yolu
            
        Returns:
            TÃ¼m analiz sonuÃ§larÄ±
        """
        try:
            print(f"\nğŸµ GELÄ°ÅMÄ°Å SES ANALÄ°ZÄ°: {os.path.basename(audio_path)}")
            print("=" * 60)
            
            # 1. Ses yÃ¼kleme ve Ã¶n iÅŸleme
            print("1. Ses yÃ¼kleniyor...")
            audio_data, sr = self.audio_processor.load_audio(audio_path)
            processed_audio = self.audio_processor.preprocess_audio(audio_data, sr)
            
            # 2. Segmentasyon - Config'den deÄŸerleri GÃœVENLÄ° ÅŸekilde al
            min_segment = (self.config.get('audio', {})
                          .get('min_segment_length', 
                               self.config.get('segmentation', {})
                               .get('min_segment_length', 0.8)))
            max_segment = (self.config.get('audio', {})
                          .get('max_segment_length',
                               self.config.get('segmentation', {})
                               .get('max_segment_length', 15.0)))
            
            print(f"2. Segmentasyon: min={min_segment}s, max={max_segment}s")
            
            segments = self.audio_processor.split_into_segments(
                processed_audio, sr,
                min_segment_length=min_segment,
                max_segment_length=max_segment
            )
            
            if not segments:
                print("âŒ HiÃ§ segment bulunamadÄ±!")
                return self._create_empty_result(audio_path, sr, audio_data)
            
            print(f"âœ… Segmentasyon tamamlandÄ±: {len(segments)} segment")
            
            # 3. Ã–zellik Ã§Ä±karÄ±mÄ±
            print("3. Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
            features_list = []
            valid_segments = []
            
            for i, segment in enumerate(segments):
                try:
                    audio_segment = segment['audio']
                    # 0.2 saniyeden kÄ±sa segmentleri atla
                    if len(audio_segment) < int(sr * 0.2):
                        continue
                    
                    features = self.feature_extractor.get_complete_feature_set(audio_segment)
                    if features and 'feature_vector' in features:
                        # Ã–zellik vektÃ¶rÃ¼nÃ¼ dÃ¼zelt (NaN'larÄ± temizle)
                        feature_vector = np.nan_to_num(features['feature_vector'], nan=0.0)
                        features_list.append(feature_vector)
                        valid_segments.append({
                            'segment_id': i,
                            'start_time': segment['start'],
                            'end_time': segment['end'],
                            'duration': segment['duration'],
                            'audio_features': features,
                            'audio_data': audio_segment
                        })
                        
                except Exception as e:
                    print(f"âŒ Segment {i} Ã¶zellik Ã§Ä±karÄ±m hatasÄ±: {e}")
                    continue
            
            print(f"âœ… BaÅŸarÄ±lÄ± Ã¶zellik Ã§Ä±karÄ±mÄ±: {len(valid_segments)}/{len(segments)} segment")
            
            if not valid_segments:
                print("âŒ Ä°ÅŸlenebilir segment bulunamadÄ±!")
                return self._create_empty_result(audio_path, sr, audio_data)
            
            # 4. GELÄ°ÅMÄ°Å KONUÅMACI ANALÄ°ZÄ°
            print("4. KonuÅŸmacÄ± analizi baÅŸlÄ±yor...")
            feature_vectors = [seg['audio_features']['feature_vector'] for seg in valid_segments]
            
            # GeliÅŸmiÅŸ konuÅŸmacÄ± tespiti
            speaker_analysis = self.speaker_clustering.advanced_speaker_detection(feature_vectors)
            
            # KonuÅŸmacÄ± ID'lerini ata
            cluster_labels = np.array(speaker_analysis.get('cluster_labels', []))
            speaker_ids = self.speaker_clustering.assign_speaker_ids(cluster_labels)
            
            # 5. GELÄ°ÅMÄ°Å CÄ°NSÄ°YET ANALÄ°ZÄ°
            print("5. Cinsiyet analizi baÅŸlÄ±yor...")
            gender_analysis = self._advanced_gender_analysis(
                [seg['audio_features'] for seg in valid_segments],
                speaker_ids
            )
            
            # 6. SONUÃ‡LARI BÄ°RLEÅTÄ°R
            print("6. SonuÃ§lar birleÅŸtiriliyor...")
            final_results = self._combine_results(
                valid_segments, speaker_analysis, gender_analysis, speaker_ids, audio_path, sr, audio_data
            )
            
            # 7. DETAYLI RAPOR
            self._generate_detailed_report(final_results)
            
            print(f"\nğŸ‰ GELÄ°ÅMÄ°Å ANALÄ°Z TAMAMLANDI!")
            return final_results
            
        except Exception as e:
            print(f"âŒ Ses iÅŸleme hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_result(audio_path, 16000, np.array([]))
    
    def _create_empty_result(self, audio_path: str, sr: int, audio_data: np.ndarray) -> Dict[str, Any]:
        """BoÅŸ sonuÃ§ oluÅŸtur"""
        return {
            'file_info': {
                'filename': os.path.basename(audio_path),
                'duration': len(audio_data) / sr if len(audio_data) > 0 else 0,
                'total_segments': 0,
                'sample_rate': sr
            },
            'speaker_analysis': {
                'speaker_count': 0,
                'speaker_ids': [],
                'cluster_labels': [],
                'embeddings': {},
                'similarity_matrix': {},
                'same_speaker_pairs': [],
                'cluster_stats': {'total_segments': 0, 'total_speakers': 0}
            },
            'gender_analysis': {
                'segment_genders': [],
                'speaker_genders': {},
                'gender_statistics': {
                    'total_predictions': 0,
                    'valid_predictions': 0,
                    'gender_distribution': {}
                }
            },
            'segments': [],
            'summary': {
                'total_speakers': 0,
                'same_speaker_alerts': 0,
                'analysis_timestamp': pd.Timestamp.now().isoformat()
            }
        }
    
    def _advanced_gender_analysis(self, audio_features: List[Dict[str, Any]], speaker_ids: List[str]) -> Dict[str, Any]:
        """
        GeliÅŸmiÅŸ cinsiyet analizi - KonuÅŸmacÄ± bazlÄ±
        """
        try:
            # Segment bazlÄ± cinsiyet tahmini
            segment_genders = self.gender_classifier.batch_predict_gender(audio_features)
            
            # KonuÅŸmacÄ± bazlÄ± cinsiyet analizi
            speaker_genders = {}
            for i, (result, speaker_id) in enumerate(zip(segment_genders, speaker_ids)):
                if speaker_id != "UNKNOWN" and result['is_valid']:
                    if speaker_id not in speaker_genders:
                        speaker_genders[speaker_id] = {
                            'gender_predictions': [],
                            'confidences': [],
                            'segment_count': 0,
                            'pitch_values': []
                        }
                    
                    speaker_genders[speaker_id]['gender_predictions'].append(result['gender'])
                    speaker_genders[speaker_id]['confidences'].append(result['confidence'])
                    speaker_genders[speaker_id]['segment_count'] += 1
                    speaker_genders[speaker_id]['pitch_values'].append(result['pitch_mean'])
            
            # Her konuÅŸmacÄ± iÃ§in nihai cinsiyet kararÄ± ver
            final_speaker_genders = {}
            for speaker_id, data in speaker_genders.items():
                if data['gender_predictions']:
                    from collections import Counter
                    gender_counter = Counter(data['gender_predictions'])
                    dominant_gender, dominant_count = gender_counter.most_common(1)[0]
                    
                    avg_confidence = np.mean(data['confidences'])
                    avg_pitch = np.mean([p for p in data['pitch_values'] if p > 0])
                    
                    consistency = dominant_count / len(data['gender_predictions'])
                    confidence_score = avg_confidence * consistency
                    
                    final_speaker_genders[speaker_id] = {
                        'final_gender': dominant_gender,
                        'confidence': round(confidence_score, 3),
                        'segment_count': data['segment_count'],
                        'consistency': round(consistency, 3),
                        'average_pitch': round(avg_pitch, 1),
                        'all_predictions': data['gender_predictions'],
                        'prediction_confidence': round(avg_confidence, 3)
                    }
            
            return {
                'segment_genders': segment_genders,
                'speaker_genders': final_speaker_genders,
                'gender_statistics': self.gender_classifier.get_gender_statistics(segment_genders)
            }
            
        except Exception as e:
            print(f"âŒ Cinsiyet analizi hatasÄ±: {e}")
            return {
                'segment_genders': [],
                'speaker_genders': {},
                'gender_statistics': {'total_predictions': 0, 'valid_predictions': 0}
            }
    
    def _combine_results(self, valid_segments: List[Dict], speaker_analysis: Dict, 
                        gender_analysis: Dict, speaker_ids: List[str], 
                        audio_path: str, sr: int, audio_data: np.ndarray) -> Dict[str, Any]:
        """
        TÃ¼m analiz sonuÃ§larÄ±nÄ± birleÅŸtir
        """
        # Ana sonuÃ§ yapÄ±sÄ±
        final_results = {
            'file_info': {
                'filename': os.path.basename(audio_path),
                'duration': len(audio_data) / sr,
                'total_segments': len(valid_segments),
                'sample_rate': sr
            },
            'speaker_analysis': speaker_analysis,
            'gender_analysis': gender_analysis,
            'segments': [],
            'summary': {
                'total_speakers': speaker_analysis.get('speaker_count', 0),
                'same_speaker_alerts': len(speaker_analysis.get('same_speaker_pairs', [])),
                'analysis_timestamp': pd.Timestamp.now().isoformat()
            }
        }
        
        # Segment detaylarÄ±nÄ± ekle
        for i, segment in enumerate(valid_segments):
            speaker_id = speaker_ids[i] if i < len(speaker_ids) else "UNKNOWN"
            segment_gender = gender_analysis['segment_genders'][i] if i < len(gender_analysis['segment_genders']) else {'gender': 'BELIRSIZ', 'confidence': 0}
            speaker_gender = gender_analysis['speaker_genders'].get(speaker_id, {})
            
            final_results['segments'].append({
                'segment_id': segment['segment_id'],
                'start_time': round(segment['start_time'], 2),
                'end_time': round(segment['end_time'], 2),
                'duration': round(segment['duration'], 2),
                'speaker_id': speaker_id,
                'gender': segment_gender.get('gender', 'BELIRSIZ'),
                'gender_confidence': segment_gender.get('confidence', 0),
                'speaker_gender': speaker_gender.get('final_gender', 'BELIRSIZ'),
                'speaker_gender_confidence': speaker_gender.get('confidence', 0),
                'pitch_mean': round(segment['audio_features'].get('pitch_mean', 0), 1),
                'energy_mean': round(segment['audio_features'].get('energy_mean', 0), 3),
                'is_valid_gender': segment_gender.get('is_valid', False)
            })
        
        return final_results
    
    def _generate_detailed_report(self, results: Dict[str, Any]):
        """DetaylÄ± analiz raporunu yazdÄ±r"""
        if not results:
            return
        
        print(f"\nğŸ“Š DETAYLI ANALÄ°Z RAPORU")
        print("=" * 60)
        
        speaker_info = results['speaker_analysis']
        gender_info = results['gender_analysis']
        
        print(f"ğŸ¯ TOPLAM KONUÅMACI SAYISI: {speaker_info['speaker_count']}")
        print(f"ğŸ“ TOPLAM SEGMENT: {results['file_info']['total_segments']}")
        print(f"â±ï¸  TOPLAM SÃœRE: {results['file_info']['duration']:.2f}s")
        
        # KonuÅŸmacÄ± detaylarÄ±
        if speaker_info['speaker_ids']:
            print(f"\nğŸ‘¥ KONUÅMACI DETAYLARI:")
            for speaker_id in speaker_info['speaker_ids']:
                segment_count = speaker_info['cluster_stats']['speaker_segment_counts'].get(speaker_id, 0)
                gender_data = gender_info['speaker_genders'].get(speaker_id, {})
                gender = gender_data.get('final_gender', 'BELIRSIZ')
                confidence = gender_data.get('confidence', 0)
                
                print(f"   {speaker_id}: {segment_count} segment | {gender} (%{confidence*100:.0f})")
        else:
            print(f"\nğŸ‘¥ KONUÅMACI DETAYLARI: HiÃ§ konuÅŸmacÄ± tespit edilemedi")
        
        # Benzerlik analizi
        similarities = speaker_info.get('similarity_matrix', {})
        if similarities:
            print(f"\nğŸ” KONUÅMACI BENZERLÄ°K ANALÄ°ZÄ°:")
            for pair, data in similarities.items():
                similarity_pct = data['similarity_percentage']
                if data['same_speaker']:
                    print(f"   âš ï¸  {pair}: AYNI KÄ°ÅÄ° OLABÄ°LÄ°R (%{similarity_pct:.1f} benzer)")
        
        # AynÄ± kiÅŸi uyarÄ±larÄ±
        same_speakers = speaker_info.get('same_speaker_pairs', [])
        if same_speakers:
            print(f"\nğŸš¨ UYARI: AYNI KÄ°ÅÄ° OLABÄ°LECEK KONUÅMACILAR:")
            for pair in same_speakers:
                print(f"   â€¢ {pair['speaker1']} â†” {pair['speaker2']} (%{pair['similarity_percentage']:.1f} benzer)")
        
        # Cinsiyet istatistikleri
        gender_stats = gender_info.get('gender_statistics', {})
        if gender_stats:
            print(f"\nğŸš» CÄ°NSÄ°YET DAÄILIMI:")
            print(f"   GeÃ§erli Tahmin: {gender_stats.get('valid_predictions', 0)}/{gender_stats.get('total_predictions', 0)}")
            if gender_stats.get('average_confidence'):
                print(f"   Ortalama GÃ¼ven: %{gender_stats['average_confidence']*100:.0f}")
            
            for gender, count in gender_stats.get('gender_distribution', {}).items():
                print(f"   {gender}: {count} segment")
    
    def export_results(self, results: Dict[str, Any], output_format: str = 'csv', 
                      output_path: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        SonuÃ§larÄ± dÄ±ÅŸa aktar
        
        Args:
            results: Analiz sonuÃ§larÄ±
            output_format: 'csv', 'excel', veya 'dataframe'
            output_path: Ã‡Ä±ktÄ± dosyasÄ± yolu
            
        Returns:
            DataFrame
        """
        try:
            if not results or 'segments' not in results or not results['segments']:
                print("âŒ DÄ±ÅŸa aktarÄ±lacak veri yok!")
                return None
            
            # DataFrame oluÅŸtur
            df = pd.DataFrame(results['segments'])
            
            # SÃ¼tunlarÄ± dÃ¼zenle
            columns_order = ['segment_id', 'start_time', 'end_time', 'duration', 
                           'speaker_id', 'gender', 'gender_confidence', 'pitch_mean', 'energy_mean']
            
            # Sadece mevcut sÃ¼tunlarÄ± kullan
            available_columns = [col for col in columns_order if col in df.columns]
            df = df[available_columns]
            
            if output_format.lower() == 'dataframe':
                return df
            
            elif output_format.lower() == 'csv':
                if not output_path:
                    base_name = results['file_info'].get('filename', 'analysis')
                    output_path = f"{base_name}_results.csv"
                
                df.to_csv(output_path, index=False, encoding='utf-8')
                print(f"âœ… CSV dosyasÄ± kaydedildi: {output_path}")
                return df
                
            elif output_format.lower() == 'excel':
                if not output_path:
                    base_name = results['file_info'].get('filename', 'analysis')
                    output_path = f"{base_name}_results.xlsx"
                
                df.to_excel(output_path, index=False)
                print(f"âœ… Excel dosyasÄ± kaydedildi: {output_path}")
                return df
            
            else:
                print(f"âŒ GeÃ§ersiz Ã§Ä±ktÄ± formatÄ±: {output_format}")
                return None
            
        except Exception as e:
            print(f"âŒ DÄ±ÅŸa aktarma hatasÄ±: {e}")
            return None
    
    def export_detailed_results(self, results: Dict[str, Any], output_path: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        DetaylÄ± sonuÃ§larÄ± dÄ±ÅŸa aktar
        """
        return self.export_results(results, 'excel', output_path)

# KullanÄ±m Ã¶rneÄŸi
if __name__ == "__main__":
    # Sistem oluÅŸtur
    diarization_system = SpeakerDiarizationSystem()
    
    # Test ses dosyasÄ± yolu
    test_audio_path = "data/raw/test_audio.wav"
    
    # EÄŸer test dosyasÄ± yoksa, demo modunda Ã§alÄ±ÅŸ
    if not os.path.exists(test_audio_path):
        print("â„¹ï¸  Test ses dosyasÄ± bulunamadÄ±, demo modunda Ã§alÄ±ÅŸÄ±lÄ±yor...")
        # Basit test sesi oluÅŸtur
        import soundfile as sf
        import numpy as np
        t = np.linspace(0, 5, 5 * 16000)
        test_audio = 0.3 * np.sin(2 * np.pi * 440 * t)
        sf.write(test_audio_path, test_audio, 16000)
        print(f"âœ… Test sesi oluÅŸturuldu: {test_audio_path}")
    
    # Ses dosyasÄ±nÄ± iÅŸle
    results = diarization_system.process_audio_file(test_audio_path)
    
    if results and results['segments']:
        # SonuÃ§larÄ± dÄ±ÅŸa aktar
        diarization_system.export_results(results, "analysis_results.csv")
        
        # Basit segment gÃ¶rÃ¼ntÃ¼leme
        print("\nğŸ“‹ Ä°LK 10 SEGMENT:")
        segments = results.get('segments', [])
        for i, result in enumerate(segments[:10]):
            print(f"   {result['segment_id']:2d}. {result['start_time']:5.1f}s - {result['end_time']:5.1f}s | "
                  f"{result['speaker_id']:6} | {result['gender']:6} | "
                  f"Pitch: {result['pitch_mean']:5.1f}Hz")
        
        if len(segments) > 10:
            print(f"   ... ve {len(segments) - 10} segment daha")
    else:
        print("âŒ Analiz sonucu alÄ±namadÄ±!")