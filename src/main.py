"""
Ana uygulama - TÃ¼m pipeline'Ä± birleÅŸtirir
"""
import numpy as np
import pandas as pd
import json
from typing import List, Dict, Any, Optional
import os
import sys

# DiÄŸer modÃ¼lleri iÃ§e aktar
from audio_processor import AudioProcessor
from feature_extractor import FeatureExtractor
from speaker_clustering import SpeakerClustering


class SpeakerDiarizationSystem:
    def __init__(self, config: Dict[str, Any] = None):
        """
        KonuÅŸmacÄ± Diarization Sistemi
        
        Args:
            config: YapÄ±landÄ±rma ayarlarÄ±
        """
        self.config = config or self._default_config()
        
        # Config'den deÄŸerleri gÃ¼venli ÅŸekilde al
        sample_rate = self.config.get('audio', {}).get('sample_rate', 16000)
        clustering_algorithm = self.config.get('clustering', {}).get('algorithm', 'dbscan')
        similarity_threshold = self.config.get('advanced_analysis', {}).get('similarity_threshold', 0.7)
        
        self.audio_processor = AudioProcessor(target_sr=sample_rate)
        self.feature_extractor = FeatureExtractor(sample_rate=sample_rate)
        self.speaker_clustering = SpeakerClustering(
            algorithm=clustering_algorithm,
            similarity_threshold=similarity_threshold
        )

        print("ğŸ‰ GeliÅŸmiÅŸ Speaker Diarization Sistemi baÅŸlatÄ±ldÄ±!")
        print(f"âš™ï¸  Sample Rate: {sample_rate}")
        print(f"âš™ï¸  Clustering Algorithm: {clustering_algorithm}")
        print(f"âš™ï¸  Similarity Threshold: {similarity_threshold}")
    
    def _default_config(self) -> Dict[str, Any]:
        """VarsayÄ±lan yapÄ±landÄ±rma"""
        return {
            'audio': {
                'sample_rate': 16000,
                'min_segment_length': 0.8,  # Daha kÄ±sa segmentlere izin ver
                'max_segment_length': 15.0  # Daha uzun segmentlere izin ver
            },
            'clustering': {
                'algorithm': 'dbscan',
                'min_speakers': 1,
                'max_speakers': 10
            },
            'segmentation': {
                'min_segment_length': 0.8,
                'max_segment_length': 15.0,
                'silence_threshold': 0.015,  # Daha hassas sessizlik tespiti
                'min_silence_length': 0.3
            },
            'advanced_analysis': {
                'similarity_threshold': 0.6,  # Daha dÃ¼ÅŸÃ¼k eÅŸik
                'min_speaker_segments': 1,    # 1 segmentli konuÅŸmacÄ±lara izin ver
                'confidence_threshold': 0.4
            }
        }
    
    def process_audio_file(self, audio_path: str) -> Dict[str, Any]:
        """
        GeliÅŸmiÅŸ ses analizi - TÃ¼m bilgileri dÃ¶ndÃ¼r
        
        Args:
            audio_path: Ses dosyasÄ± yolu
            
        Returns:
            TÃ¼m analiz sonuÃ§larÄ±
        """
        try:
            print(f"\nğŸµ GELÄ°ÅMÄ°Å SES ANALÄ°ZÄ°: {os.path.basename(audio_path)}")
            print("=" * 60)
            
            # 1. Ses yÃ¼kleme ve Ã¶n iÅŸleme
            print("1. Ses yÃ¼kleniyor...")
            audio_data, sr = self.audio_processor.load_audio(audio_path)
            processed_audio = self.audio_processor.preprocess_audio(audio_data, sr)
            
            # 2. Segmentasyon - Config'den deÄŸerleri GÃœVENLÄ° ÅŸekilde al
            min_segment = (self.config.get('audio', {})
                          .get('min_segment_length', 
                               self.config.get('segmentation', {})
                               .get('min_segment_length', 0.8)))
            max_segment = (self.config.get('audio', {})
                          .get('max_segment_length',
                               self.config.get('segmentation', {})
                               .get('max_segment_length', 15.0)))
            
            print(f"2. Segmentasyon: min={min_segment}s, max={max_segment}s")
            
            segments = self.audio_processor.split_into_segments(
                processed_audio, sr,
                min_segment_length=min_segment,
                max_segment_length=max_segment
            )
            
            if not segments:
                print("âŒ HiÃ§ segment bulunamadÄ±!")
                return self._create_empty_result(audio_path, sr, audio_data)
            
            print(f"âœ… Segmentasyon tamamlandÄ±: {len(segments)} segment")
            
            # 3. Ã–zellik Ã§Ä±karÄ±mÄ±
            print("3. Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
            features_list = []
            valid_segments = []
            
            for i, segment in enumerate(segments):
                try:
                    audio_segment = segment['audio']
                    # 0.2 saniyeden kÄ±sa segmentleri atla
                    if len(audio_segment) < int(sr * 0.2):
                        continue
                    
                    features = self.feature_extractor.get_complete_feature_set(audio_segment)
                    if features and 'feature_vector' in features:
                        # Ã–zellik vektÃ¶rÃ¼nÃ¼ dÃ¼zelt (NaN'larÄ± temizle)
                        feature_vector = np.nan_to_num(features['feature_vector'], nan=0.0)
                        features_list.append(feature_vector)
                        valid_segments.append({
                            'segment_id': i,
                            'start_time': segment['start'],
                            'end_time': segment['end'],
                            'duration': segment['duration'],
                            'audio_features': features,
                            'audio_data': audio_segment
                        })
                        
                except Exception as e:
                    print(f"âŒ Segment {i} Ã¶zellik Ã§Ä±karÄ±m hatasÄ±: {e}")
                    continue
            
            print(f"âœ… BaÅŸarÄ±lÄ± Ã¶zellik Ã§Ä±karÄ±mÄ±: {len(valid_segments)}/{len(segments)} segment")
            
            if not valid_segments:
                print("âŒ Ä°ÅŸlenebilir segment bulunamadÄ±!")
                return self._create_empty_result(audio_path, sr, audio_data)
            
            # 4. GELÄ°ÅMÄ°Å KONUÅMACI ANALÄ°ZÄ°
            print("4. KonuÅŸmacÄ± analizi baÅŸlÄ±yor...")
            feature_vectors = [seg['audio_features']['feature_vector'] for seg in valid_segments]
            
            # GeliÅŸmiÅŸ konuÅŸmacÄ± tespiti
            speaker_analysis = self.speaker_clustering.advanced_speaker_detection(feature_vectors)
            
            # KonuÅŸmacÄ± ID'lerini ata
            cluster_labels = np.array(speaker_analysis.get('cluster_labels', []))
            speaker_ids = self.speaker_clustering.assign_speaker_ids(cluster_labels)
            
            # 6. SONUÃ‡LARI BÄ°RLEÅTÄ°R
            print("6. SonuÃ§lar birleÅŸtiriliyor...")
            final_results = self._combine_results(
                valid_segments, speaker_analysis, speaker_ids, audio_path, sr, audio_data
            )
            
            # 7. DETAYLI RAPOR
            self._generate_detailed_report(final_results)
            
            print(f"\nğŸ‰ GELÄ°ÅMÄ°Å ANALÄ°Z TAMAMLANDI!")
            return final_results
            
        except Exception as e:
            print(f"âŒ Ses iÅŸleme hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_result(audio_path, 16000, np.array([]))
    
    def _create_empty_result(self, audio_path: str, sr: int, audio_data: np.ndarray) -> Dict[str, Any]:
        """BoÅŸ sonuÃ§ oluÅŸtur"""
        return {
            'file_info': {
                'filename': os.path.basename(audio_path),
                'duration': len(audio_data) / sr if len(audio_data) > 0 else 0,
                'total_segments': 0,
                'sample_rate': sr
            },
            'speaker_analysis': {
                'speaker_count': 0,
                'speaker_ids': [],
                'cluster_labels': [],
                'embeddings': {},
                'similarity_matrix': {},
                'same_speaker_pairs': [],
                'cluster_stats': {'total_segments': 0, 'total_speakers': 0}
            },
            'segments': [],
            'summary': {
                'total_speakers': 0,
                'same_speaker_alerts': 0,
                'analysis_timestamp': pd.Timestamp.now().isoformat()
            }
        }
    
    def _combine_results(self, valid_segments: List[Dict], speaker_analysis: Dict, 
                     speaker_ids: List[str], 
                     audio_path: str, sr: int, audio_data: np.ndarray) -> Dict[str, Any]:
     """
     TÃ¼m analiz sonuÃ§larÄ±nÄ± birleÅŸtir (cinsiyet bilgisi hariÃ§)
     """
     # Ana sonuÃ§ yapÄ±sÄ±
     final_results = {
        'file_info': {
            'filename': os.path.basename(audio_path),
            'duration': len(audio_data) / sr,
            'total_segments': len(valid_segments),
            'sample_rate': sr
        },
        'speaker_analysis': speaker_analysis,
        'segments': [],
        'summary': {
            'total_speakers': speaker_analysis.get('speaker_count', 0),
            'same_speaker_alerts': len(speaker_analysis.get('same_speaker_pairs', [])),
            'analysis_timestamp': pd.Timestamp.now().isoformat()
        }
    }
    
     for i, segment in enumerate(valid_segments):
        speaker_id = speaker_ids[i] if i < len(speaker_ids) else "UNKNOWN"
        
        final_results['segments'].append({
            'segment_id': segment['segment_id'],
            'start_time': round(segment['start_time'], 2),
            'end_time': round(segment['end_time'], 2),
            'duration': round(segment['duration'], 2),
            'speaker_id': speaker_id,
            'pitch_mean': round(segment['audio_features'].get('pitch_mean', 0), 1),
            'energy_mean': round(segment['audio_features'].get('energy_mean', 0), 3)
        })
    
     return final_results

    def _generate_detailed_report(self, results: Dict[str, Any]):
     """DetaylÄ± analiz raporunu yazdÄ±r (cinsiyet bilgisi hariÃ§)"""
     if not results:
        return
    
     print(f"\nğŸ“Š DETAYLI ANALÄ°Z RAPORU")
     print("=" * 60)
    
     speaker_info = results['speaker_analysis']
    
     print(f"ğŸ¯ TOPLAM KONUÅMACI SAYISI: {speaker_info['speaker_count']}")
     print(f"ğŸ“ TOPLAM SEGMENT: {results['file_info']['total_segments']}")
     print(f"â±ï¸  TOPLAM SÃœRE: {results['file_info']['duration']:.2f}s")
    
     # KonuÅŸmacÄ± detaylarÄ±
     if speaker_info['speaker_ids']:
        print(f"\nğŸ‘¥ KONUÅMACI DETAYLARI:")
        for speaker_id in speaker_info['speaker_ids']:
            segment_count = speaker_info['cluster_stats']['speaker_segment_counts'].get(speaker_id, 0)
            print(f"   {speaker_id}: {segment_count} segment")
     else:
        print(f"\nğŸ‘¥ KONUÅMACI DETAYLARI: HiÃ§ konuÅŸmacÄ± tespit edilemedi")
    
     # Benzerlik analizi
     similarities = speaker_info.get('similarity_matrix', {})
     if similarities:
        print(f"\nğŸ” KONUÅMACI BENZERLÄ°K ANALÄ°ZÄ°:")
        for pair, data in similarities.items():
            similarity_pct = data['similarity_percentage']
            if data['same_speaker']:
                print(f"   âš ï¸  {pair}: AYNI KÄ°ÅÄ° OLABÄ°LÄ°R (%{similarity_pct:.1f} benzer)")
    
     # AynÄ± kiÅŸi uyarÄ±larÄ±
     same_speakers = speaker_info.get('same_speaker_pairs', [])
     if same_speakers:
        print(f"\nğŸš¨ UYARI: AYNI KÄ°ÅÄ° OLABÄ°LECEK KONUÅMACILAR:")
        for pair in same_speakers:
            print(f"   â€¢ {pair['speaker1']} â†” {pair['speaker2']} (%{pair['similarity_percentage']:.1f} benzer)")
    
    def generate_report(self, results: Dict[str, Any], output_path: Optional[str] = None) -> None:
        """
        Pipeline uyumluluÄŸu iÃ§in: detaylÄ± raporu yazdÄ±rÄ±r ve JSON/CSV gibi Ã§Ä±ktÄ± oluÅŸturur.
        """
        # Konsola detaylÄ± rapor bas
        self._generate_detailed_report(results)

        # EÄŸer output_path verilmiÅŸse JSON olarak kaydet
        if output_path:
            try:
                import json
                with open(output_path, "w", encoding="utf-8") as f:
                   json.dump(results, f, ensure_ascii=False, indent=2, default=str)
                print(f"âœ… JSON raporu kaydedildi: {output_path}")
            except Exception as e:
                print(f"âŒ JSON raporu kaydedilemedi: {e}")


    def export_results(self, results: Dict[str, Any], output_format: str = 'csv', 
                       output_path: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        SonuÃ§larÄ± dÄ±ÅŸa aktar
        """
        try:
            if not results or 'segments' not in results or not results['segments']:
                print("âŒ DÄ±ÅŸa aktarÄ±lacak veri yok!")
                return None
            
            df = pd.DataFrame(results['segments'])
            
            columns_order = [
                'segment_id', 'start_time', 'end_time', 'duration',
                'speaker_id', 'pitch_mean', 'energy_mean'
            ]
            available_columns = [col for col in columns_order if col in df.columns]
            df = df[available_columns]
            
            if output_format.lower() == 'dataframe':
                return df
            elif output_format.lower() == 'csv':
                output_path = output_path or f"{results['file_info']['filename']}_results.csv"
                df.to_csv(output_path, index=False, encoding='utf-8')
                print(f"âœ… CSV dosyasÄ± kaydedildi: {output_path}")
                return df
            elif output_format.lower() == 'excel':
                output_path = output_path or f"{results['file_info']['filename']}_results.xlsx"
                df.to_excel(output_path, index=False)
                print(f"âœ… Excel dosyasÄ± kaydedildi: {output_path}")
                return df
            else:
                print(f"âŒ GeÃ§ersiz Ã§Ä±ktÄ± formatÄ±: {output_format}")
                return None

        except Exception as e:
            print(f"âŒ DÄ±ÅŸa aktarma hatasÄ±: {e}")
            return None
